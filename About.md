I'm mostly a portrait photographer with a double training in classical music (piano) and hardware "low-tech" engineering (mechanics and metrology, Newtonian physics and the likes). I taught music for a while and I currently teach post-processing with darktable. 

I have been an user of darktable since its 0.9 version, somewhere circa 2011. At that time, I didn't even know how to program. I joined darktable's development in 2018 at first to solve the color issues that arose when editing large dynamic range pictures, which led to filmic and later filmic RGB modules, then to the whole scene-referred workflow. For that, I learned from scratch to program in C, OpenCL, with OpenMP, for GPU and though Git. 4 years later, I'm one of the few guys who can start from an artistic visual intent to achieve, work out the maths to get it done, turn the math into an efficient program, build an user GUI around it and produce videos and docs to explain how to use it.

Before 2018, I did mostly B&W photography because I couldn't get the colors I wanted. I gradually extended the scene-referred pipeline with the ASC-CDL mode in color balance, then color balance RGB, tone equalizer, color calibration (and its built-in color checker profiling tool), and negadoctor for film digitizing. I'm happy to report than I now get the colors I wanted and that darktable lets you build your own virtual film emulsion.

I like minimalistic design, so I build generic tools that can be used for a variety of uses (including unplanned and uncharted uses) rather than specific tools that essentially duplicate the same pixel code under different interfaces for the sake of guiding (but restraining) users. It's amazing, when you pick an old mechanical film SLR, to see that you can achieve with 3 very general controls (focusing ring, aperture ring, shutter speed dial) the same things as we do now with dozens of specialized sub-menus to set-up. The digital bloat sure makes SLR faster and more reliable to operate in certain contexts, but they also add to the cognitive overload by requiring too much attention to too many parameters that anyway still control only the same 4 general parameters : shutter speed, aperture, sensitivity, focusing. It's a difficult trade-off to find between too many options and too little control, and only Fuji X has managed to nail ergonomics (if only they didn't go full X-Trans…), but more options is not systematically equivalent to more control, and generality helps in that context.

I also like physics and clean math. Building on the physical accuracy of the scene-referred pipeline, I developed the blurs module which simulates lens and motion blur with physically-accurate models. I extended the Fourier [heat equation](https://en.wikipedia.org/wiki/Heat_equation) to the 4th order in a [wavelets framework](https://en.wikipedia.org/wiki/Spline_wavelet#Cubic_B-spline) and to anisotropic diffusion, at first to produce watercolour-like smudges, and then figured it could be extended to deblurring and dehazing by simply subtracting instead of adding the diffusion term… which gave birth to the diffuse or sharpen module in darktable 3.8. Though I still have mixed feelings about enabling the sharpness addicts to overcook every picture in ways that don't improve its artistic quality. 

Before that, I had worked on [experimental blind deconvolution methods](https://github.com/aurelienpierre/Image-Cases-Studies) to recover pictures from missed focus and lens blur, but gave up on implementing them in darktable since the runtimes were unrealistic and the results unpredictable (diffuse or sharpen is more robust and already quite slow to run, but much faster).

Reusing that 4th order diffusion model in wavelets space, I invented the joint guided laplacian + RGB ratios diffusion method to reconstruct clipped highlights in 3D, added in darktable 4.0. This one accidentally qualifies as a supervised machine learning algorithm for gradient-based optimization. Fancy words to say that we reconstruct damaged parts of the image by filling them with synthetic content that extrapolates the gradients from the valid parts in a smooth way.

In early 2022, I developed a new [uniform color space](https://eng.aurelienpierre.com/2022/02/color-saturation-control-for-the-21th-century/) specifically for the needs of the color balance RGB, that allows to manipulate saturation for artistic purposes with account for the [Helmholtz-Kohlrausch effect](https://en.wikipedia.org/wiki/Helmholtz%E2%80%93Kohlrausch_effect). It's one of the two only usable color spaces for that purpose, the other one having been published in March 2022 but with a different goal.

Developing for darktable is my full-time job, paid by the users who think it's worth it, and it's no secret that I couldn't have done all that in less than 4 years otherwise since pretty much all of it is original work. It wasn't my goal to become opensource dev, but since nobody else would fix all that, there is not much of an alternative. There are worse jobs though than designing artistic tools for visual expression in a methodic and rigorous way, while being able to enforce my own standards of quality rather than having to dumb down and half-ass stuff because corporate said marketing said consumers said "good enough" is too complicated.

More importantly, I dabble in 14 programming languages while I hate computers, programming and high technology (aka stuff I can't repair myself with a wrench). I would still be running Windows XP if it was still supported, and I don't give a flying shit about trending techs… They are all a waste of energy and doped silicon brought to you by capitalists to keep selling useless products to people who have already all they need and more than they deserve.

I use Linux because it's the shitty OS that lets me hack it when I'm really annoyed, but I'm not an opensource evangelist and I'm firmly convinced that Linux sucks as much as Windows or Mac. It's just that Linux has a hood that can be opened with an engine that can be hacked, while the others are pretty much black boxes that work better in a large variety of cases. The fact that opensource seems to be the universal excuse for "not working" pisses me off to the maximum level and I don't believe in software developed non-professionally on saturdays, because thinking it through takes too much time for that paradigm. Hobby-based development is more suitable for the immediate reward contained in half-assed hacks.